# Sen1floods11 Dataset

## Presentation

Sen1Floods11: a georeferenced dataset to train and test deep learning flood algorithms for Sentinel-1 (Example). This data was generated by Cloud to Street, a Public Benefit Corporation: https://www.cloudtostreet.info/. For questions about this dataset or code please email support@cloudtostreet.info. Please cite this data as:

Bonafilia, D., Tellman, B., Anderson, T., Issenberg, E. 2020. Sen1Floods11: a georeferenced dataset to train and test deep learning flood algorithms for Sentinel-1. The IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, 2020, pp. 210-211.

Available Open access at: http://openaccess.thecvf.com/content_CVPRW_2020/html/w11/Bonafilia_Sen1Floods11_A_Georeferenced_Dataset_to_Train_and_Test_Deep_Learning_CVPRW_2020_paper.html

## Getting started

### Get Started with DVC

#### Prerequisites

As a prerequisite for using DVC, you must have a Git repository initialized :

```bash
git clone https://gitlab.develop.eoepca.org/sharinghub-test/sen1floods11-dataset.git
```

#### Authenticate DVC

Configure your authentication (will be only stored locally)

```bash
dvc remote modify --local workspace access_key_id 'mysecret'
dvc remote modify --local workspace secret_access_key 'mysecret'
```

#### Tracking data

Working inside an initialized project directory, let's pick a piece of data to work with. We'll use an example `very_big_file.txt` file, in the `data` directory.

```bash
echo "very big content" > data/very_big_file.txt
```

Use `dvc add` to start tracking the dataset file:

```bash
dvc add data/very_big_file.txt
```

DVC stores information about the added file in a special `.dvc` file named `data/very_big_file.txt.dvc`. This small, human-readable metadata file acts as a placeholder for the original data for the purpose of Git tracking.

Next, run the following commands to track changes in Git:

```bash
git add data
git commit -m "chore: add raw data"
dvc push
git git push --set-upstream origin main
```

### Load the Dataset with Hugging Face datasets library

```python
from datasets import load_dataset

train_data = load_dataset(
                "sen1floods11-dataset/sen1floods11_dataset.py",
                split="train",
                streaming=True,
                trust_remote_code=True,
                config_kwargs={
                    "no_cache": no_cache,
                    "context": "sen1floods11-dataset/",
                },
            )
print(next(iter(train_data)))
```